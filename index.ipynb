{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Extensions to Linear Models - Lab"]},{"cell_type":"markdown","metadata":{},"source":["## Introduction\n","\n","In this lab, you'll practice many concepts you have learned so far, from adding interactions and polynomials to your model to regularization!"]},{"cell_type":"markdown","metadata":{},"source":["## Summary\n","\n","You will be able to:\n","\n","- Build a linear regression model with interactions and polynomial features \n","- Use feature selection to obtain the optimal subset of features in a dataset"]},{"cell_type":"markdown","metadata":{},"source":["## Let's Get Started!\n","\n","Below we import all the necessary packages for this lab."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Run this cell without changes\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings('ignore')\n","from itertools import combinations\n","\n","from sklearn.feature_selection import RFE\n","from sklearn.linear_model import LinearRegression, Lasso\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures"]},{"cell_type":"markdown","metadata":{},"source":["Load the data."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Run this cell without changes\n","\n","# Load data from CSV\n","df = pd.read_csv(\"ames.csv\")\n","# Subset columns\n","df = df[['LotArea', 'OverallQual', 'OverallCond', 'TotalBsmtSF',\n","         '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'TotRmsAbvGrd',\n","         'GarageArea', 'Fireplaces', 'SalePrice']]\n","\n","# Split the data into X and y\n","y = df['SalePrice']\n","X = df.drop(columns='SalePrice')\n","\n","# Split into train, test, and validation sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=0)"]},{"cell_type":"markdown","metadata":{},"source":["## Build a Baseline Housing Data Model"]},{"cell_type":"markdown","metadata":{},"source":["Above, we imported the Ames housing data and grabbed a subset of the data to use in this analysis.\n","\n","Next steps:\n","\n","- Scale all the predictors using `StandardScaler`, then convert these scaled features back into DataFrame objects\n","- Build a baseline `LinearRegression` model using *scaled variables* as predictors and use the $R^2$ score to evaluate the model "]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["    LotArea  OverallQual  OverallCond  TotalBsmtSF  1stFlrSF  2ndFlrSF  \\\n","0 -0.114710    -0.099842    -0.509252    -0.639316 -0.804789  1.261552   \n","1 -0.176719     0.632038    -0.509252     0.838208  0.641608 -0.808132   \n","2 -0.246336    -0.831723     1.304613    -0.012560 -0.329000 -0.808132   \n","3 -0.378617    -0.831723     1.304613    -0.339045 -0.609036 -0.808132   \n","4 -0.010898    -1.563603     1.304613    -2.531499 -1.315922  0.550523   \n","\n","   GrLivArea  TotRmsAbvGrd  GarageArea  Fireplaces  \n","0   0.499114      0.250689    0.327629   -0.994820  \n","1  -0.247249     -0.365525    0.079146   -0.994820  \n","2  -0.944766     -0.981739   -1.105931   -0.994820  \n","3  -1.146010     -0.981739   -1.134602    0.588023  \n","4  -0.481708      0.250689   -2.281450   -0.994820  \n","    LotArea  OverallQual  OverallCond  TotalBsmtSF  1stFlrSF  2ndFlrSF  \\\n","0 -0.491264    -0.099842     0.397681    -0.248487 -0.598161 -0.808132   \n","1 -0.619291     0.632038    -0.509252    -0.205591 -0.549222  0.849426   \n","2  0.240165    -0.099842     0.397681    -0.639316 -1.044043  0.722619   \n","3  0.037695     2.095798    -3.230050     1.891539  1.843314 -0.808132   \n","4 -0.147924     0.632038    -0.509252    -1.616388 -0.995104  0.709032   \n","\n","   GrLivArea  TotRmsAbvGrd  GarageArea  Fireplaces  \n","0  -1.138195     -0.981739   -0.178895   -0.994820  \n","1   0.327177      0.250689   -0.465607   -0.994820  \n","2  -0.137834     -0.365525   -0.427379   -0.994820  \n","3   0.616344      0.866903    1.703847    0.588023  \n","4  -0.114388      0.250689   -0.408265    0.588023  \n","    LotArea  OverallQual  OverallCond  TotalBsmtSF  1stFlrSF  2ndFlrSF  \\\n","0 -0.206088    -0.099842     2.211546    -0.007794 -0.299094 -0.808132   \n","1  0.108211     1.363918    -0.509252     0.954980  0.875424  1.732552   \n","2 -0.161422    -0.831723     0.397681    -0.129332 -0.407845 -0.808132   \n","3 -0.485374    -0.099842     1.304613    -0.138864 -0.473096  0.686388   \n","4  0.160731     2.095798    -0.509252     1.329127  1.201679 -0.808132   \n","\n","   GrLivArea  TotRmsAbvGrd  GarageArea  Fireplaces  \n","0  -0.923274     -0.365525   -1.019917   -0.994820  \n","1   2.112978      1.483117    1.120866    2.170867  \n","2  -1.001427     -0.981739   -0.561178    0.588023  \n","3   0.241209      0.250689   -0.274466    2.170867  \n","4   0.155240     -0.365525    2.076573    0.588023  \n"]}],"source":["# Your code here\n","\n","# Scale X_train and X_val using StandardScaler\n","scaler = StandardScaler()\n","\n","# Ensure X_train and X_val are scaled DataFrames\n","# (hint: you can set the columns using X.columns)\n","#fit the scaler on the training data and transform it\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_val_scaled = scaler.transform(X_val)\n","X_test_scaled = scaler.transform(X_test)\n","#Convert scaled features into dataframes\n","X_train_scaled_df = pd.DataFrame(X_train_scaled,columns = X_train.columns)\n","X_val_scaled_df = pd.DataFrame(X_val_scaled,columns = X_val.columns)\n","X_test_scaled_df = pd.DataFrame(X_test_scaled,columns = X_test.columns)\n","#display output\n","print(X_train_scaled_df.head())\n","print(X_val_scaled_df.head())\n","print(X_test_scaled_df.head())"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training R2_score: 0.7868\n"]}],"source":["# Your code here\n","from sklearn.metrics import r2_score\n","# Create a LinearRegression model and fit it on scaled training data\n","linreg = LinearRegression()\n","#fit the model on the scaled training data\n","linreg.fit(X_train_scaled_df,y_train)\n","#predict on the training set\n","y_train_pred = linreg.predict(X_train_scaled_df)\n","# Calculate a baseline r-squared score on training data\n","r2_train = r2_score(y_train,y_train_pred)\n","print(f\"Training R2_score: {r2_train:.4f}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Add Interactions\n","\n","Instead of adding all possible interaction terms, let's try a custom technique. We are only going to add the interaction terms that increase the $R^2$ score as much as possible. Specifically we are going to look for the 7 interaction terms that each cause the most increase in the coefficient of determination.\n","\n","### Find the Best Interactions\n","\n","Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Create a data structure that stores the pair of columns used as well as the $R^2$ score for each combination.\n","\n","***Hint:*** We have imported the `combinations` function from `itertools` for you ([documentation here](https://docs.python.org/3/library/itertools.html#itertools.combinations)). Try applying this to the columns of `X_train` to find all of the possible pairs.\n","\n","Print the 7 interactions that result in the highest $R^2$ scores."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Top 7 Interactions that Increase the R^2 Score the Most:\n","1. Interaction: ('OverallQual', 'GarageArea'), R^2 Score: 0.8172\n","2. Interaction: ('OverallQual', 'Fireplaces'), R^2 Score: 0.8135\n","3. Interaction: ('OverallQual', 'TotRmsAbvGrd'), R^2 Score: 0.8104\n","4. Interaction: ('OverallQual', 'GrLivArea'), R^2 Score: 0.8100\n","5. Interaction: ('OverallQual', 'TotalBsmtSF'), R^2 Score: 0.8100\n","6. Interaction: ('GrLivArea', 'Fireplaces'), R^2 Score: 0.8080\n","7. Interaction: ('OverallQual', '1stFlrSF'), R^2 Score: 0.8049\n"]}],"source":["from itertools import combinations\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import r2_score\n","import pandas as pd\n","\n","# Step 1: Generate All Possible Combinations of Columns\n","column_pairs = list(combinations(X_train_scaled_df.columns, 2))\n","\n","# Store the results in a list\n","interaction_results = []\n","\n","# Step 2: Add Interaction Terms and Evaluate R^2 Score\n","for pair in column_pairs:\n","    # Create the interaction term\n","    X_train_interaction = X_train_scaled_df.copy()\n","    interaction_term = X_train_scaled_df[pair[0]] * X_train_scaled_df[pair[1]]\n","    interaction_name = f\"{pair[0]}_x_{pair[1]}\"\n","    \n","    # Add the interaction term to the DataFrame\n","    X_train_interaction[interaction_name] = interaction_term\n","    \n","    # Fit the model and calculate R^2 score\n","    linreg = LinearRegression()\n","    linreg.fit(X_train_interaction, y_train)\n","    y_train_pred = linreg.predict(X_train_interaction)\n","    r2_score_value = r2_score(y_train, y_train_pred)\n","    \n","    # Store the pair and its R^2 score\n","    interaction_results.append((pair, r2_score_value))\n","\n","# Step 3: Sort the Results by R^2 Score\n","interaction_results.sort(key=lambda x: x[1], reverse=True)\n","\n","# Step 4: Print the Top 7 Interactions\n","top_7_interactions = interaction_results[:7]\n","print(\"Top 7 Interactions that Increase the R^2 Score the Most:\")\n","for idx, result in enumerate(top_7_interactions, 1):\n","    print(f\"{idx}. Interaction: {result[0]}, R^2 Score: {result[1]:.4f}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### Add the Best Interactions\n","\n","Write code to include the 7 most important interactions in `X_train` and `X_val` by adding 7 columns. Use the naming convention `\"col1_col2\"`, where `col1` and `col2` are the two columns in the interaction."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train with Interaction Terms:\n","    LotArea  OverallQual  OverallCond  TotalBsmtSF  1stFlrSF  2ndFlrSF  \\\n","0 -0.114710    -0.099842    -0.509252    -0.639316 -0.804789  1.261552   \n","1 -0.176719     0.632038    -0.509252     0.838208  0.641608 -0.808132   \n","2 -0.246336    -0.831723     1.304613    -0.012560 -0.329000 -0.808132   \n","3 -0.378617    -0.831723     1.304613    -0.339045 -0.609036 -0.808132   \n","4 -0.010898    -1.563603     1.304613    -2.531499 -1.315922  0.550523   \n","\n","   GrLivArea  TotRmsAbvGrd  GarageArea  Fireplaces  OverallQual_GarageArea  \\\n","0   0.499114      0.250689    0.327629   -0.994820               -0.032711   \n","1  -0.247249     -0.365525    0.079146   -0.994820                0.050023   \n","2  -0.944766     -0.981739   -1.105931   -0.994820                0.919828   \n","3  -1.146010     -0.981739   -1.134602    0.588023                0.943674   \n","4  -0.481708      0.250689   -2.281450   -0.994820                3.567282   \n","\n","   OverallQual_Fireplaces  OverallQual_TotRmsAbvGrd  OverallQual_GrLivArea  \\\n","0                0.099325                 -0.025029              -0.049833   \n","1               -0.628764                 -0.231026              -0.156271   \n","2                0.827414                  0.816535               0.785783   \n","3               -0.489072                  0.816535               0.953163   \n","4                1.555503                 -0.391978               0.753200   \n","\n","   OverallQual_TotalBsmtSF  GrLivArea_Fireplaces  OverallQual_1stFlrSF  \n","0                 0.063831             -0.496529              0.080352  \n","1                 0.529779              0.245968              0.405521  \n","2                 0.010446              0.939872              0.273637  \n","3                 0.281991             -0.673881              0.506549  \n","4                 3.958259              0.479213              2.057579  \n","\n","X_val with Interaction Terms:\n","    LotArea  OverallQual  OverallCond  TotalBsmtSF  1stFlrSF  2ndFlrSF  \\\n","0 -0.491264    -0.099842     0.397681    -0.248487 -0.598161 -0.808132   \n","1 -0.619291     0.632038    -0.509252    -0.205591 -0.549222  0.849426   \n","2  0.240165    -0.099842     0.397681    -0.639316 -1.044043  0.722619   \n","3  0.037695     2.095798    -3.230050     1.891539  1.843314 -0.808132   \n","4 -0.147924     0.632038    -0.509252    -1.616388 -0.995104  0.709032   \n","\n","   GrLivArea  TotRmsAbvGrd  GarageArea  Fireplaces  OverallQual_GarageArea  \\\n","0  -1.138195     -0.981739   -0.178895   -0.994820                0.017861   \n","1   0.327177      0.250689   -0.465607   -0.994820               -0.294281   \n","2  -0.137834     -0.365525   -0.427379   -0.994820                0.042671   \n","3   0.616344      0.866903    1.703847    0.588023                3.570920   \n","4  -0.114388      0.250689   -0.408265    0.588023               -0.258039   \n","\n","   OverallQual_Fireplaces  OverallQual_TotRmsAbvGrd  OverallQual_GrLivArea  \\\n","0                0.099325                  0.098019               0.113640   \n","1               -0.628764                  0.158445               0.206788   \n","2                0.099325                  0.036495               0.013762   \n","3                1.232379                  1.816853               1.291733   \n","4                0.371653                  0.158445              -0.072298   \n","\n","   OverallQual_TotalBsmtSF  GrLivArea_Fireplaces  OverallQual_1stFlrSF  \n","0                 0.024810              1.132299              0.059722  \n","1                -0.129941             -0.325482             -0.347129  \n","2                 0.063831              0.137120              0.104240  \n","3                 3.964284              0.362425              3.863215  \n","4                -1.021618             -0.067263             -0.628944  \n"]}],"source":["# Assuming top_7_interactions is the list of top 7 interactions obtained from the previous step\n","# and X_train_scaled_df and X_val_scaled_df are your scaled DataFrames for training and validation sets\n","\n","# Add the top 7 interactions to X_train and X_val\n","for pair, _ in top_7_interactions:\n","    # Create the interaction term\n","    interaction_name = f\"{pair[0]}_{pair[1]}\"\n","    \n","    # Add interaction term to X_train\n","    X_train_scaled_df[interaction_name] = X_train_scaled_df[pair[0]] * X_train_scaled_df[pair[1]]\n","    \n","    # Add interaction term to X_val\n","    X_val_scaled_df[interaction_name] = X_val_scaled_df[pair[0]] * X_val_scaled_df[pair[1]]\n","\n","# Display the first few rows to check the new columns\n","print(\"X_train with Interaction Terms:\")\n","print(X_train_scaled_df.head())\n","\n","print(\"\\nX_val with Interaction Terms:\")\n","print(X_val_scaled_df.head())\n"]},{"cell_type":"markdown","metadata":{},"source":["## Add Polynomials\n","\n","Now let's repeat that process for adding polynomial terms.\n","\n","### Find the Best Polynomials\n","\n","Try polynomials of degrees 2, 3, and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of degree 4 with `PolynomialFeatures`, the particular column is raised to the power of 2 and 3 as well in other terms.\n","\n","We only want to include \"pure\" polynomials, so make sure no interactions are included.\n","\n","Once again you should make a data structure that contains the values you have tested. We recommend a list of tuples of the form:\n","\n","`(col_name, degree, R2)`, so eg. `('OverallQual', 2, 0.781)` "]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Top Polynomial Terms that Increase the R^2 Score the Most:\n","Column: OverallQual_1stFlrSF, Degree: 4, R^2 Score: 0.8774\n","Column: 1stFlrSF, Degree: 4, R^2 Score: 0.8763\n","Column: OverallQual_1stFlrSF, Degree: 3, R^2 Score: 0.8732\n","Column: 1stFlrSF, Degree: 3, R^2 Score: 0.8648\n","Column: OverallQual_1stFlrSF, Degree: 2, R^2 Score: 0.8613\n","Column: OverallQual_TotalBsmtSF, Degree: 4, R^2 Score: 0.8538\n","Column: TotalBsmtSF, Degree: 4, R^2 Score: 0.8529\n"]}],"source":["from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import r2_score\n","import pandas as pd\n","\n","# Initialize an empty list to store the results\n","polynomial_results = []\n","\n","# Step 1: Generate and Evaluate Polynomial Terms for Each Column\n","for col in X_train_scaled_df.columns:\n","    for degree in [2, 3, 4]:\n","        # Create polynomial features of the specified degree for the column\n","        poly = PolynomialFeatures(degree=degree, include_bias=False)\n","        X_poly_train = poly.fit_transform(X_train_scaled_df[[col]])\n","        X_poly_val = poly.transform(X_val_scaled_df[[col]])\n","\n","        # We only want the pure polynomial term (e.g., col^2, col^3, col^4)\n","        poly_col_name = f\"{col}^{degree}\"\n","        \n","        # Add the polynomial term to the DataFrame\n","        X_train_poly = X_train_scaled_df.copy()\n","        X_train_poly[poly_col_name] = X_poly_train[:, -1]\n","        \n","        # Fit the model with the polynomial term\n","        linreg = LinearRegression()\n","        linreg.fit(X_train_poly, y_train)\n","        y_train_pred = linreg.predict(X_train_poly)\n","        \n","        # Calculate the R^2 score\n","        r2_train = r2_score(y_train, y_train_pred)\n","        \n","        # Store the result as a tuple: (column name, degree, R^2 score)\n","        polynomial_results.append((col, degree, r2_train))\n","\n","# Step 2: Sort the Results by R^2 Score\n","polynomial_results.sort(key=lambda x: x[2], reverse=True)\n","\n","# Step 3: Print the Top Polynomial Terms\n","print(\"Top Polynomial Terms that Increase the R^2 Score the Most:\")\n","for col, degree, r2 in polynomial_results[:7]:  # Print the top 7 results\n","    print(f\"Column: {col}, Degree: {degree}, R^2 Score: {r2:.4f}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### Add the Best Polynomials\n","\n","If there are duplicate column values in the results above, don't add multiple of them to the model, to avoid creating duplicate columns. (For example, if column `A` appeared in your list as both a 2nd and 3rd degree polynomial, adding both would result in `A` squared being added to the features twice.) Just add in the polynomial that results in the highest R-Squared."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train with Polynomial Terms:\n","    LotArea  OverallQual  OverallCond  TotalBsmtSF  1stFlrSF  2ndFlrSF  \\\n","0 -0.114710    -0.099842    -0.509252    -0.639316 -0.804789  1.261552   \n","1 -0.176719     0.632038    -0.509252     0.838208  0.641608 -0.808132   \n","2 -0.246336    -0.831723     1.304613    -0.012560 -0.329000 -0.808132   \n","3 -0.378617    -0.831723     1.304613    -0.339045 -0.609036 -0.808132   \n","4 -0.010898    -1.563603     1.304613    -2.531499 -1.315922  0.550523   \n","\n","   GrLivArea  TotRmsAbvGrd  GarageArea  Fireplaces  ...  \\\n","0   0.499114      0.250689    0.327629   -0.994820  ...   \n","1  -0.247249     -0.365525    0.079146   -0.994820  ...   \n","2  -0.944766     -0.981739   -1.105931   -0.994820  ...   \n","3  -1.146010     -0.981739   -1.134602    0.588023  ...   \n","4  -0.481708      0.250689   -2.281450   -0.994820  ...   \n","\n","   OverallQual_Fireplaces^4  2ndFlrSF^4  OverallCond^2  \\\n","0                  0.000097    2.532911       0.259338   \n","1                  0.156297    0.426509       0.259338   \n","2                  0.468697    0.426509       1.702016   \n","3                  0.057213    0.426509       1.702016   \n","4                  5.854419    0.091854       1.702016   \n","\n","   OverallQual_TotRmsAbvGrd^3  LotArea^2  OverallQual_GarageArea^3  \\\n","0                   -0.000016   0.013158                 -0.000035   \n","1                   -0.012331   0.031230                  0.000125   \n","2                    0.544407   0.060682                  0.778250   \n","3                    0.544407   0.143351                  0.840361   \n","4                   -0.060226   0.000119                 45.395438   \n","\n","   OverallQual^2  GarageArea^3  Fireplaces^2  TotRmsAbvGrd^2  \n","0       0.009968      0.035168      0.989667        0.062845  \n","1       0.399472      0.000496      0.989667        0.133609  \n","2       0.691762     -1.352645      0.989667        0.963812  \n","3       0.691762     -1.460598      0.345772        0.963812  \n","4       2.444854    -11.874980      0.989667        0.062845  \n","\n","[5 rows x 34 columns]\n","\n","X_val with Polynomial Terms:\n","    LotArea  OverallQual  OverallCond  TotalBsmtSF  1stFlrSF  2ndFlrSF  \\\n","0 -0.491264    -0.099842     0.397681    -0.248487 -0.598161 -0.808132   \n","1 -0.619291     0.632038    -0.509252    -0.205591 -0.549222  0.849426   \n","2  0.240165    -0.099842     0.397681    -0.639316 -1.044043  0.722619   \n","3  0.037695     2.095798    -3.230050     1.891539  1.843314 -0.808132   \n","4 -0.147924     0.632038    -0.509252    -1.616388 -0.995104  0.709032   \n","\n","   GrLivArea  TotRmsAbvGrd  GarageArea  Fireplaces  ...  \\\n","0  -1.138195     -0.981739   -0.178895   -0.994820  ...   \n","1   0.327177      0.250689   -0.465607   -0.994820  ...   \n","2  -0.137834     -0.365525   -0.427379   -0.994820  ...   \n","3   0.616344      0.866903    1.703847    0.588023  ...   \n","4  -0.114388      0.250689   -0.408265    0.588023  ...   \n","\n","   OverallQual_Fireplaces^4  2ndFlrSF^4  OverallCond^2  \\\n","0                  0.000097    0.426509       0.158150   \n","1                  0.156297    0.520599       0.259338   \n","2                  0.000097    0.272670       0.158150   \n","3                  2.306622    0.426509      10.433223   \n","4                  0.019079    0.252734       0.259338   \n","\n","   OverallQual_TotRmsAbvGrd^3  LotArea^2  OverallQual_GarageArea^3  \\\n","0                    0.000942   0.241340                  0.000006   \n","1                    0.003978   0.383521                 -0.025485   \n","2                    0.000049   0.057679                  0.000078   \n","3                    5.997351   0.001421                 45.534462   \n","4                    0.003978   0.021881                 -0.017181   \n","\n","   OverallQual^2  GarageArea^3  Fireplaces^2  TotRmsAbvGrd^2  \n","0       0.009968     -0.005725      0.989667        0.963812  \n","1       0.399472     -0.100939      0.989667        0.062845  \n","2       0.009968     -0.078062      0.989667        0.133609  \n","3       4.392371      4.946429      0.345772        0.751520  \n","4       0.399472     -0.068050      0.345772        0.062845  \n","\n","[5 rows x 34 columns]\n"]}],"source":["# Dictionary to store the best polynomial for each column\n","best_polynomials = {}\n","\n","# Populate the dictionary with the best polynomial term for each column\n","for col, degree, r2 in polynomial_results:\n","    if col not in best_polynomials:\n","        best_polynomials[col] = (degree, r2)\n","\n","# Now add these best polynomials to the DataFrames\n","for col, (degree, _) in best_polynomials.items():\n","    # Create polynomial features of the specified degree for the column\n","    poly = PolynomialFeatures(degree=degree, include_bias=False)\n","    X_poly_train = poly.fit_transform(X_train_scaled_df[[col]])\n","    X_poly_val = poly.transform(X_val_scaled_df[[col]])\n","    \n","    # Add the highest degree term to the DataFrames\n","    poly_col_name = f\"{col}^{degree}\"\n","    X_train_scaled_df[poly_col_name] = X_poly_train[:, -1]\n","    X_val_scaled_df[poly_col_name] = X_poly_val[:, -1]\n","\n","# Display the updated DataFrames with the new polynomial terms\n","print(\"X_train with Polynomial Terms:\")\n","print(X_train_scaled_df.head())\n","\n","print(\"\\nX_val with Polynomial Terms:\")\n","print(X_val_scaled_df.head())\n"]},{"cell_type":"markdown","metadata":{},"source":["Check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here"]},{"cell_type":"markdown","metadata":{},"source":["## Full Model R-Squared"]},{"cell_type":"markdown","metadata":{},"source":["Check out the $R^2$ of the full model with your interaction and polynomial terms added. Print this value for both the train and validation data."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here"]},{"cell_type":"markdown","metadata":{},"source":["It looks like we may be overfitting some now. Let's try some feature selection techniques."]},{"cell_type":"markdown","metadata":{},"source":["## Feature Selection\n","\n","First, test out `RFE` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html)) with several different `n_features_to_select` values. For each value, print out the train and validation $R^2$ score and how many features remain."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here\n"]},{"cell_type":"markdown","metadata":{},"source":["Now test out `Lasso` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)) with several different `alpha` values."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here\n"]},{"cell_type":"markdown","metadata":{},"source":["Compare the results. Which features would you choose to use?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your written answer here"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluate Final Model on Test Data\n","\n","### Data Preparation\n","\n","At the start of this lab, we created `X_test` and `y_test`. Prepare `X_test` the same way that `X_train` and `X_val` have been prepared. This includes scaling, adding interactions, and adding polynomial terms."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here\n"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluation"]},{"cell_type":"markdown","metadata":{},"source":["Using either `RFE` or `Lasso`, fit a model on the complete train + validation set, then find R-Squared and MSE values for the test set."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here\n"]},{"cell_type":"markdown","metadata":{},"source":["## Level Up Ideas (Optional)\n","\n","### Create a Lasso Path\n","\n","From this section, you know that when using `Lasso`, more parameters shrink to zero as your regularization parameter goes up. In scikit-learn there is a function `lasso_path()` which visualizes the shrinkage of the coefficients while $alpha$ changes. Try this out yourself!\n","\n","https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py\n","\n","### AIC and BIC for Subset Selection\n","\n","This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Ames housing data!\n","\n","https://xavierbourretsicotte.github.io/subset_selection.html"]},{"cell_type":"markdown","metadata":{},"source":["## Summary"]},{"cell_type":"markdown","metadata":{},"source":["Congratulations! You now know how to apply concepts of bias-variance tradeoff using extensions to linear models and feature selection."]}],"metadata":{"kernelspec":{"display_name":"learn-env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":4}
